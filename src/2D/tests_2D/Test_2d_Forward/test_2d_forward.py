# -*- coding: utf-8 -*-
"""
Test suite for the two‑dimensional forward Cahn–Hilliard solver.

This module contains a comprehensive set of unit and integration tests that
exercise the forward time integration of the Cahn–Hilliard equation in
two spatial dimensions.  The forward solver implements a Crank–Nicolson
scheme with adaptive time stepping, Neumann boundary conditions and a
Newton–Raphson inner solve.  The tests verify the following aspects:

* **Spatial discretisation:** The discrete Laplacian matrix generated by
  ``laplacian_matrix_neumann`` is applied to a known cosine function and
  compared against the analytical second derivative.
* **Random initial condition:** The helper ``init_phi_random`` is tested for
  zero‐mean and bound preservation under a trapezoidal quadrature.
* **Auxiliary variable update:** The closed form update for the auxiliary
  variable ``w`` is compared to ``solve_w`` for 2‑D arrays.
* **Mass conservation:** In the absence of control, the mass (integral over
  space) of the solution should be conserved.  A log plot of the absolute
  mass deviation is saved for visual inspection, and the maximum deviation
  is required to stay below a tiny tolerance.
* **Energy decay:** The free energy of the Cahn–Hilliard system is a Lyapunov
  functional under the chosen time discretisation; it must decrease (or at
  worst remain constant) at each time step.
* **Symmetry preservation:** A symmetric initial condition should remain
  symmetric under the evolution; this test monkey‐patches the random
  initialiser to return a symmetric field and then checks the final state.
* **Temporal convergence:** By refining the time step and comparing against a
  reference solution, the temporal order of accuracy of the scheme is
  estimated from a log–log slope; it should be approximately second order.
* **Unconditional stability:** Large time steps should not cause blow up;
  the solution must remain finite even when ``dt`` is large.
* **Linear stability:** For small perturbations, the growth rate of the
  linearised system can be computed analytically; the numerical scheme is
  compared against this theory.
* **Newton–Raphson convergence:** The non–linear solve inside each time
  step should converge quadratically; the residuals from the Newton solver
  are inspected to confirm this behaviour.

The plotting code in the tests writes figures into a ``test_plots`` directory
so that automated test runs do not open GUI windows.  Most assertions are
written in terms of relative errors and simple inequalities to ensure that
the properties hold to machine precision.  The tests are designed to be
self‐contained and fast to run on coarse grids.
"""

import numpy as np
import pytest
import matplotlib.pyplot as plt
from numpy.testing import assert_allclose
# Project functions


from Forward2_solver import (
    laplacian_matrix_neumann,
    apply_laplacian,
    run_main_simulation,
    trapz_weights,
    free_energy,
    init_phi_random,
    newton_raphson,
    
    solve_w,
    # optional helpers if you compute Newton residuals explicitly:
    initialize_mu,
    
    
)
# Configured input (like 1-D tests)
from config import ForwardSolverConfig
#import io, re, numpy as np
#from contextlib import redirect_stdout, redirect_stder

# -------- helpers (same as 1-D style) --------
EPS = np.finfo(float).eps
TINY = 1e-16
DELTA_SEP = 1e-2

# --- add these imports right after the module docstring ---
import os
os.environ.setdefault("MPLBACKEND", "Agg")   # headless plotting for CI/Spyder/Jupyter
import matplotlib
matplotlib.use("Agg", force=True)

plt.ioff()  # never open interactive windows

# --- create a shared plot dir (same as 1-D) ---
PLOT_DIR = "test_plots"
os.makedirs(PLOT_DIR, exist_ok=True)

def rel_residual(res, *terms):
    denom = sum(np.linalg.norm(t) for t in terms) + TINY
    return np.linalg.norm(res) / denom

def auto_tol_from_cond(A, base=1e3):
    """Estimate tol from cond(A). Safe for small test matrices (dense if needed)."""
    try:
        c = np.linalg.cond(A.toarray())
        if not np.isfinite(c):
            c = 1e12
    except Exception:
        c = 1e6
    return base * EPS * max(1.0, c), c

def auto_tol_scalar(base=1e3):
    return base * EPS

# ========= fixtures =========

@pytest.fixture(scope="module")
def cfg():
    """Default 2-D forward config (like 1-D tests use ForwardSolverConfig defaults)."""
    return ForwardSolverConfig()

@pytest.fixture
def solver_params_2d(cfg: ForwardSolverConfig):
    """Provides grid & operators for 2-D tests, derived from config (no globals)."""
    Nx, Ny = cfg.Nx, cfg.Ny
    Lx, Ly = cfg.Lx, cfg.Ly
    hx, hy = Lx / Nx, Ly / Ny

    x = np.linspace(0.0, Lx, Nx + 1)
    y = np.linspace(0.0, Ly, Ny + 1)
    X, Y = np.meshgrid(x, y, indexing="ij")
    Lmat = laplacian_matrix_neumann(Nx, Ny, hx, hy)

    return {
        "Nx": Nx, "Ny": Ny,
        "Lx": Lx, "Ly": Ly,
        "hx": hx, "hy": hy,
        "x": x, "y": y, "X": X, "Y": Y, "Lmat": Lmat,
        "kappa": cfg.kappa, "c1": cfg.c1, "c2": cfg.c2,
        "tau": cfg.tau, "gamma": cfg.gamma,
    }

@pytest.fixture
def grid_setup():
    """Small synthetic grids for cost-term isolation tests (kept minimal)."""
    Nx_cost, Ny_cost, M_cost = 4, 3, 5
    Lx_cost, Ly_cost, T_cost = 1.0, 1.0, 1.0
    x = np.linspace(0.0, Lx_cost, Nx_cost + 1)
    y = np.linspace(0.0, Ly_cost, Ny_cost + 1)
    t_hist = np.linspace(0.0, T_cost, M_cost + 1)
    shape = (M_cost + 1, Nx_cost + 1, Ny_cost + 1)
    return dict(Nx=Nx_cost, Ny=Ny_cost, M=M_cost,
                Lx=Lx_cost, Ly=Ly_cost, T=T_cost,
                x=x, y=y, t_hist=t_hist, shape=shape)


# ========= Laplacian & forward tests =========




def test_laplacian_matrix_on_known_function_2d(solver_params_2d):
    """Apply the discrete Laplacian to a known eigenfunction and compare.

    A cosine mode ``cos(pi x / Lx) cos(pi y / Ly)`` is an eigenfunction of the
    Laplacian with eigenvalue ``-(pi/Lx)^2 - (pi/Ly)^2``.  This test applies
    the discrete Laplacian matrix to this mode and asserts that the interior
    values match the analytical eigenvalue times the function.  Boundary
    points are excluded from the comparison because of the discrete Neumann
    implementation.
    """
    p = solver_params_2d
    X, Y, Lmat = p["X"], p["Y"], p["Lmat"]
    Lx, Ly = p["Lx"], p["Ly"]
    v = np.cos(np.pi * X / Lx) * np.cos(np.pi * Y / Ly)
    analytical = -((np.pi/Lx)**2 + (np.pi/Ly)**2) * v
    numerical = apply_laplacian(Lmat, v, p["Nx"], p["Ny"])
    assert_allclose(numerical[1:-1, 1:-1], analytical[1:-1, 1:-1],
                    rtol=1e-3, atol=1e-8,
                    err_msg="2D Laplacian operator does not match analytical solution.")

def test_initial_phi_properties_2d(solver_params_2d):
    """Validate the random initial condition generator.

    The function ``init_phi_random`` produces a random field with zero mean
    (with respect to the trapezoidal weights) and values strictly inside
    ``(-1 + DELTA_SEP, 1 - DELTA_SEP)``.  This test computes the weighted
    mean and checks the maximum absolute value of the random initial field.
    """
    p = solver_params_2d
    phi0 = init_phi_random(p["Nx"], p["Ny"], DELTA_SEP, amp=1,enforce_zero_mean=True)
    # 2D trapezoid weights: outer(wy, wx)
    wts_x = trapz_weights(p["Nx"] + 1)
    wts_y = trapz_weights(p["Ny"] + 1)
    wts_2d = np.outer(wts_x, wts_y)  # (Nx+1, Ny+1)  # (Ny+1, Nx+1)
    mean_val = np.sum(wts_2d * phi0) / np.sum(wts_2d)
    assert_allclose(mean_val, 0, atol=5e-14, err_msg="Initial 2D phi should have zero mean.")
    assert np.all(np.abs(phi0) <= 1 - DELTA_SEP), "Initial 2D phi values exceed safety bounds."

def test_solve_w_simple_case_2d(solver_params_2d, cfg: ForwardSolverConfig):
    """Check the closed form update for the auxiliary variable ``w`` in 2‑D.

    For a constant ``w_old`` and constant control values ``u_n`` and
    ``u_{n+1}``, there is an analytic expression for ``w^{n+1}`` derived
    from the Crank–Nicolson update.  This test asserts that the function
    ``solve_w`` matches that expression elementwise.
    """
    p = solver_params_2d
    w_old = np.ones((p["Ny"] + 1, p["Nx"] + 1)) * 0.1
    u_n = np.ones((p["Ny"] + 1, p["Nx"] + 1)) * 0.5
    u_np1 = np.ones((p["Ny"] + 1, p["Nx"] + 1)) * 0.5
    dt = 0.1
    gamma_dt = cfg.gamma / dt
    expected = ((gamma_dt - 0.5) * w_old + 0.5 * (u_np1 + u_n)) / (gamma_dt + 0.5)
    calc = solve_w(w_old, dt, cfg.gamma, u_n, u_np1)
    assert_allclose(calc, expected, rtol=1e-15, err_msg="solve_w incorrect for 2D arrays.")

# ========= Integration tests =========

def test_mass_conservation_without_control_2d(cfg: ForwardSolverConfig, solver_params_2d):
    """Ensure that the total mass (integral of ``phi``) is conserved.

    The forward solver is run with no control input.  The trapezoidal rule is
    used to approximate the spatial integral of ``phi`` at each time step.
    A semilog plot of the absolute mass deviation is saved and the maximum
    deviation is asserted to be below a stringent tolerance.
    """
    # run_main_simulation now accepts the configuration as the first positional argument named 'config'
    phi_hist, (x, y), t_hist = run_main_simulation(cfg, store_history=True, verbose=False)

    # trapezoid weights (2D)
    wts_x = trapz_weights(cfg.Nx + 1)
    wts_y = trapz_weights(cfg.Ny + 1)
    wts_2d = np.outer(wts_x, wts_y)

    # mass over time (use *all* steps for the plot)
    mass = np.array([np.sum(wts_2d * phi) for phi in phi_hist])
    M0 = mass[0]
    abs_err = np.abs(mass - M0)
    tol = 1e-11  # absolute mass tolerance

    # ---- plot (same style as 1-D) ----
    fig, ax = plt.subplots(figsize=(6.5, 4.0))
    ax.semilogy(abs_err + 1e-30, 'b-', lw=1.5, label=r"$|M(t)-M(0)|$")
    ax.axhline(tol, color='r', ls='--', lw=1.0, label=fr"Tolerance = {tol:g}")
    ax.set_title("Mass Conservation (Absolute Error) – 2D", fontsize=16)
    ax.set_xlabel("Time Step", fontsize=14)
    ax.set_ylabel("absolute mass deviation", fontsize=14)
    ax.grid(True, which="both", ls=":", alpha=0.6)
    ax.legend(loc="upper right")
    fig.tight_layout()
    fig.savefig(os.path.join(PLOT_DIR, "test_mass_conservation_abs_error_2d.png"), dpi=200)
    plt.close(fig)

    # strict criterion (same spirit as 1-D)
    assert abs_err.max() <= tol, f"Max mass deviation {abs_err.max():.3e} exceeds tol {tol:g}"


def test_energy_decrease_without_control_2d(cfg: ForwardSolverConfig, solver_params_2d):
    """Check that the free energy decreases monotonically over time.

    The free energy functional is computed at each time level.  A plot of
    the energy versus time is generated and the differences between
    successive energies are asserted to be nonpositive up to a tiny
    numerical tolerance.  This confirms the dissipative nature of the
    discrete scheme.
    """
    phi_hist, (x, y), t_hist = run_main_simulation(cfg, store_history=True, verbose=False)
    p = solver_params_2d

    energy_over_time = [free_energy(phi, p["kappa"], p["c1"], p["c2"], p["hx"], p["hy"])
                        for phi in phi_hist]

    # ---- plot (same look as 1-D) ----
    fig, ax = plt.subplots(figsize=(7.0, 4.5), constrained_layout=True)
    ax.plot(energy_over_time, 'k-')
    ax.set_title("Free Energy Decrease Over Time – 2D", fontsize=16, pad=10)
    ax.set_xlabel("Time Step", fontsize=14, labelpad=6)
    ax.set_ylabel("Free Energy", fontsize=14, labelpad=6)
    ax.grid(True, ls=":", alpha=0.7)
    fig.savefig(os.path.join(PLOT_DIR, "test_energy_decrease_2d.png"), dpi=200, bbox_inches="tight")
    plt.close(fig)

    # monotonic non-increase
    diffs = np.diff(energy_over_time)
    assert np.all(diffs <= 1e-9), f"Energy increased at some steps (max +Δ={diffs.max():.2e})"


def test_symmetry_preservation_2d(cfg: ForwardSolverConfig, solver_params_2d):
    """Verify that a symmetric initial condition remains symmetric.

    A symmetric cosine profile is used to initialise the simulation by
    monkey‐patching ``init_phi_random``.  After a forward run the final
    state is compared to its left–right mirror image to machine precision.
    """
    Lx = cfg.Lx
    x = np.linspace(0, Lx, cfg.Nx + 1)
    symmetric_phi0 = 0.5 * np.cos(2 * np.pi * x / Lx)
    symmetric_phi0 = np.tile(symmetric_phi0[:, None], (1, cfg.Ny + 1))
    # Monkeypatch initializer
    original_init = __import__('Forward2_solver').init_phi_random
    __import__('Forward2_solver').init_phi_random = lambda *args, **kwargs: symmetric_phi0.copy()
    phi_hist, (x, y), t_hist = run_main_simulation(cfg, store_history=True, verbose=False)
    __import__('Forward2_solver').init_phi_random = original_init
    final_phi = phi_hist[-1]
    assert_allclose(final_phi, np.fliplr(final_phi), atol=1e-8,err_msg="Symmetry not preserved in 2D.")




def test_time_integrator_convergence_order_2d(cfg: ForwardSolverConfig):
    """Estimate the temporal order of accuracy of the forward integrator.

    By running the solver with progressively smaller time steps over a
    short horizon and comparing against a reference solution obtained with
    a very fine time step, the L2 error is computed.  A log–log fit
    estimates the slope (order of convergence) which should be close to 2
    for a second‐order Crank–Nicolson scheme.  A convergence plot is saved
    for visual confirmation.
    """
    """Check order ~2 by refining dt; use short T to keep runtime small."""
    base_dt = 0.005
    short_T = 5 * base_dt

    # Reference with finer dt
    fcfg = ForwardSolverConfig(**{**cfg.dict(), "dt_initial": base_dt/8.0, "T": short_T})
    phi_fine, _, _ = run_main_simulation(fcfg, store_history=True, verbose=False)
    phi_ref_final = phi_fine[-1]

    errors = []
    dt_values = np.array([base_dt, base_dt/2.0, base_dt/4.0])
    for dtc in dt_values:
        ccfg = ForwardSolverConfig(**{**cfg.dict(), "dt_initial": dtc, "T": short_T})
        phi_c, _, _ = run_main_simulation(ccfg, store_history=True, verbose=False)
        errors.append(np.linalg.norm(phi_c[-1] - phi_ref_final))

    slope, _ = np.polyfit(np.log(dt_values), np.log(np.array(errors) + 1e-30), 1)

    # Generate and save a log–log convergence plot for visual inspection. The reference slope of 2
    # is plotted alongside the numerical slope obtained from the simulation. This helps to
    # illustrate the second-order temporal accuracy of the integrator.
    try:
        # ---- plot (match 1-D style + 2-D filename) ----
        fig, ax = plt.subplots()
        ax.loglog(dt_values, errors, 'bo-', label=f'Numerical (Slope ≈ {slope:.2f})')
        # Reference order-2 line anchored at the first point
        ref = (errors[0] / (dt_values[0]**2)) * dt_values**2
        ax.loglog(dt_values, ref, 'r--', label='Theoretical Order 2')
        ax.set_title("Time Integrator Convergence Order – 2D", fontsize=16)
        ax.set_xlabel("Time Step (Δt)", fontsize=14)
        ax.set_ylabel("L2 Error", fontsize=14)
        ax.grid(True, which="both", ls="--", alpha=0.6)
        ax.legend()
        ax.invert_xaxis()   # same visual as 1-D
        fig.tight_layout()
        fig.savefig(os.path.join(PLOT_DIR, "test_convergence_order_2d.png"), dpi=200)
        plt.close(fig)

    except Exception:
        # Silently ignore any plotting errors to avoid test failures
        pass

    assert 1 < slope < 2.2, f"Expected ~2nd-order in time, got slope={slope:.4f}"

def test_unconditional_stability_with_large_dt_2d(cfg: ForwardSolverConfig):
    """Test that the scheme remains stable for a very large time step.

    The forward solver is run with a single very large ``dt``.  The final
    state is checked to ensure there are no NaNs or infinities.  This
    demonstrates the unconditional stability of the implicit discretisation.
    """
    large_dt = 1.0
    scfg = ForwardSolverConfig(**{**cfg.dict(), "dt_initial": large_dt, "T": 3*large_dt})
    phi_hist, _, _ = run_main_simulation(scfg, store_history=True, verbose=False)
    final_phi = phi_hist[-1]
    assert np.all(np.isfinite(final_phi)), "Non-finite values with large dt → instability."

def test_linear_stability_growth_rate_2d(solver_params_2d, cfg: ForwardSolverConfig):
    """Compare numerical and analytical growth rates for a linearised mode.

    A small amplitude cosine mode with known wavenumbers is evolved for a
    very short time.  The analytical growth rate of the linearised
    Cahn–Hilliard equation is computed and compared to the numerical
    logarithmic growth rate.  Agreement to a few percent confirms the
    linear stability characteristics of the discretisation.
    """
    p = solver_params_2d
    Lx, Ly = p["Lx"], p["Ly"]
    # pick unstable mode
    kx = 4 * np.pi / Lx
    ky = 2 * np.pi / Ly
    k2 = kx**2 + ky**2
    theoretical = (k2 * (2*p["c2"] - 2*p["c1"] - p["kappa"]*k2)) / (1 + p["tau"] * k2)
    amp = 1e-4
    X, Y = p["X"], p["Y"]
    phi0 = amp * np.cos(kx * X) * np.cos(ky * Y)
    # monkeypatch init; run short
    original_init = __import__('Forward2_solver').init_phi_random
    __import__('Forward2_solver').init_phi_random = lambda *args, **kwargs: phi0.copy()
    short_T = 1e-5
    fine_dt = cfg.dt_initial / 10.0
    scfg = ForwardSolverConfig(**{**cfg.dict(), "dt_initial": fine_dt, "T": short_T})
    phi_hist, _, _ = run_main_simulation(scfg, store_history=True, verbose=False)
    __import__('Forward2_solver').init_phi_random = original_init
    final_phi = phi_hist[-1]
    numerical = np.log(np.linalg.norm(final_phi) / np.linalg.norm(phi0)) / short_T
    assert_allclose(numerical, theoretical, rtol=1e-2,
                    err_msg="Numerical growth rate ≠ linear theory in 2D.")
    
    
def test_newton_raphson_quadratic_convergence_2d(solver_params_2d, cfg: ForwardSolverConfig):
    """Check that the Newton–Raphson solver exhibits quadratic convergence.

    The non–linear solve inside the Crank–Nicolson time stepping uses a
    Newton–Raphson iteration.  This test calls the solver with a
    reproducible initial condition and either captures the residual history
    from the return value or parses it from stdout.  It then performs
    standard checks: monotonic decrease of residuals, final residual below
    tolerance, and approximate quadratic convergence based on the slope of
    successive log residuals.  A short tail of the residual history is
    inspected for robustness.
    """
    """
    Quadratic convergence check for the 2-D Newton solver.
    Prefer residual history returned by the solver; otherwise parse printed norms.
    """
    import io, re
    import contextlib

    p = solver_params_2d
    # Build consistent initial state (match solver parameters)
    phi_old = init_phi_random(p["Nx"], p["Ny"], DELTA_SEP, seed=99)
    w_old   = np.zeros_like(phi_old)
    mu_old  = initialize_mu(phi_old, w_old, p["c1"], p["c2"], cfg.kappa,
                            p["Lmat"], p["Nx"], p["Ny"], DELTA_SEP)
    w_new   = w_old + 0.01

    # Try to call with residual history; fall back if not supported
    buf_out, buf_err = io.StringIO(), io.StringIO()
    with contextlib.redirect_stdout(buf_out), contextlib.redirect_stderr(buf_err):
        try:
            ret = newton_raphson(
                phi_old, mu_old, w_old, w_new,
                cfg.dt_initial, cfg.tau, p["c1"], p["c2"], cfg.kappa, DELTA_SEP,
                p["Lmat"], p["Nx"], p["Ny"], p["hx"], p["hy"],
                return_residual_history=True
            )
        except TypeError:
            ret = newton_raphson(
                phi_old, mu_old, w_old, w_new,
                cfg.dt_initial, cfg.tau, p["c1"], p["c2"], cfg.kappa, DELTA_SEP,
                p["Lmat"], p["Nx"], p["Ny"], p["hx"], p["hy"]
            )

    # Unpack return (2-tuple or 3-tuple)
    if isinstance(ret, tuple) and len(ret) == 3:
        phi_new, mu_new, residuals_from_solver = ret
    elif isinstance(ret, tuple) and len(ret) == 2:
        phi_new, mu_new = ret
        residuals_from_solver = None
    else:
        raise TypeError(f"Unexpected return from newton_raphson: {type(ret)}")

    # Use returned history if available; else parse prints robustly
    if residuals_from_solver is not None:
        res = np.asarray(residuals_from_solver, dtype=float)
    else:
        text = buf_out.getvalue() + "\n" + buf_err.getvalue()
        # extract ANY floats (incl. scientific) from stdout/stderr
        nums = re.findall(r'(?<![\w.])[-+]?(?:\d+\.?\d*|\.\d+)(?:[eE][-+]?\d+)?(?![\w.])', text)
        vals = [float(s) for s in nums]
        res = np.asarray([v for v in vals if np.isfinite(v) and v > 0], dtype=float)

    tol = 1e-6
    print("\n--- Newton residuals (2D) ---")
    print(" iter | residual")
    for k, r in enumerate(res):
        print(f"{k:5d} | {r:.6e}")
    print(f"tolerance = {tol:.1e}")

    # Sanity
    assert res.size >= 2, f"Captured too few Newton iterations: {res}"

    # Use the last few values (tail) for monotonic & slope checks
    tail = res[-4:] if res.size >= 4 else res

    # Monotone decrease (allow tiny numerical wiggle)
    assert np.all(tail[1:] <= tail[:-1] + 1e-12), f"Residuals not decreasing near end: {tail}"

    # Final tolerance
    assert tail[-1] < tol, f"Final residual too large: {tail[-1]:.3e} (history: {res})"

    # Quadratic hallmark: log(e_{k+1}) ~ 2*log(e_k) + const → slope ≈ 2
    if tail.size >= 3:
        logs_k   = np.log(tail[:-1] + 1e-300)
        logs_k1  = np.log(tail[1:]  + 1e-300)
        slope, _ = np.polyfit(logs_k, logs_k1, 1)
        assert 1.5 < slope < 2.5, f"Expected ~quadratic slope ~2, got {slope:.2f} (tail={tail})"

    # If only 2 points are available, we already enforced monotone decrease and final tol.
    
    
if __name__ == "__main__":
    # Run pytest programmatically
    
    pytest.main([__file__, "-v","-s", "--tb=short"])